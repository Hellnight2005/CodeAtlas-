@startuml
title DFD Level 2 - Detailed Process View - CodeAtlas

!theme plain
hide empty members

entity "User" as User
entity "GitHub API" as GitHub

storage "MySQL (Repo DB)" as MySQL
storage "Kafka\n(repo-files-processing)" as Kafka1
storage "Kafka\n(repo-files-with-content)" as Kafka2
storage "Neo4j (Graph DB)" as Neo4j

rectangle "Git Auth Service" {
    process "1.1 Receive & Validate Request" as P1_1
    process "1.2 Fetch Repository Tree" as P1_2
    process "1.3 Initialize Metadata" as P1_3
    process "1.4 Publish File Events" as P1_4
}

rectangle "Repo Parser Service" {
    process "2.1 Consume File Event" as P2_1
    process "2.2 Fetch File Content" as P2_2
    process "2.3 Store Raw Content" as P2_3
    process "2.4 Generate AST & Normalize" as P2_4
    process "2.5 Broadcast Enriched Data" as P2_5
    process "2.6 Export to Neo4j" as P2_6
}

' Flow - Git Auth
User --> P1_1 : Request Repo
P1_1 --> P1_2 : Validated
P1_2 --> GitHub : Get Recursive Tree
GitHub --> P1_2 : Tree JSON
P1_2 --> P1_3 : Tree Data
P1_3 --> MySQL : Insert (Status: Pending)
P1_3 --> P1_4 : File Metadata
P1_4 --> Kafka1 : Produce (Path, SHA)

' Flow - Repo Parser
Kafka1 --> P2_1 : Consume
P2_1 --> P2_2 : File Info
P2_2 --> GitHub : Get Blob/Content
GitHub --> P2_2 : Base64 Content
P2_2 --> P2_3 : Raw Content
P2_3 --> MySQL : Update raw_content
P2_3 --> P2_4 : Content Ready
P2_4 --> P2_4 : Parse & Normalize
P2_4 --> MySQL : Update sorted_content (AST)
P2_4 --> P2_5 : Enriched Event
P2_5 --> Kafka2 : Produce (AST Data)
P2_4 --> P2_6 : Graph Nodes Ready
P2_6 --> Neo4j : Cypher Merge

@enduml
